// Copyright 2016 Google Inc. All rights reserved.
// Use of this source code is governed by the Apache 2.0
// license that can be found in the LICENSE file.

package testutil

import (
	"fmt"
	"strconv"
	"sync/atomic"
	"testing"
	"time"

	gocontext "golang.org/x/net/context"

	"strings"

	"cloud.google.com/go/storage"
	"google.golang.org/api/iterator"
)

var (
	idCounter uint64
	expiry    = time.Hour
)

const appPrefix = "golang_samples"

// CleanupBuckets deletes all the expired and given buckets.
// If a bucket contains objects, it first deletes all the objects.
func CleanupBuckets(t *testing.T, name ...string) {
	ctx := gocontext.Background()
	tc := SystemTest(t)

	client, err := storage.NewClient(ctx)
	if err != nil {
		t.Errorf("Cannot create client: %v", err)
		return // Will be cleanuped when expired
	}

	biter := client.Buckets(ctx, tc.ProjectID)
	for {
		b, err := biter.Next()
		if err != nil {
			break // Ignore errors, deletion will be retried at the next cleanup.
		}
		bucket := b.Name
		t, ok := extractTime(bucket)
		if ok && t.Before(time.Now().Add(-expiry)) {
			name = append(name, bucket)
		}
	}

	for _, b := range name {
		bucket := client.Bucket(b)
		it := bucket.Objects(ctx, nil)

		// Delete all objects belongs to the bucket.
		// If deletion fails, skip to the next bucket,
		// next cleanup job will delete the garbage bucket.
		for {
			o, err := it.Next()
			if err == iterator.Done {
				break
			}
			if err != nil {
				// Ignore, will expire and deleted in the future.
				t.Logf("Cannot iterate objects (bucket=%v): %v", b, err)
				break
			}
			Retry(t, 10, time.Second, func(r *R) {
				if err := bucket.Object(o.Name).Delete(ctx); err != nil {
					// Ignore, will expire and deleted in the future.
					r.Errorf("cannot clean up object (bucket=%v, object=%v): %v", b, o.Name, err)
				}
			})

		}
		Retry(t, 10, time.Second, func(r *R) {
			if err := bucket.Delete(ctx); err != nil {
				// Ignore, will expire and deleted in the future.
				r.Errorf("cannot clean up bucket (bucket=%v): %v", b, err)
			}
		})
	}
}

// NextBucket will return a new unique bucket name for the given namespace.
func NextBucket(namespace string) string {
	atomic.AddUint64(&idCounter, 1)
	return fmt.Sprintf("%s_%s_bucket%d_%d", appPrefix, namespace, idCounter, time.Now().Unix())
}

// NextObject will return a new unique object name for the given namespace.
func NextObject(namespace string) string {
	atomic.AddUint64(&idCounter, 1)
	return fmt.Sprintf("%s_%s_object%d_%d", appPrefix, namespace, idCounter, time.Now().Unix())
}

// BucketsMustExist makes sure the given list of buckets exists.
// It creates the given bucket names if there are no matching buckets already.
// If any error occurs during creation or checking the existence, it fails
// the current test case.
func BucketsMustExist(t *testing.T, name ...string) {
	ctx := gocontext.Background()
	tc := SystemTest(t)

	client, err := storage.NewClient(ctx)
	if err != nil {
		t.Fatalf("BucketsMustExist cannot create client: %v", err)
	}

	for _, n := range name {
		b := client.Bucket(n)
		_, err = b.Attrs(ctx)
		if err == storage.ErrBucketNotExist {
			err = b.Create(ctx, tc.ProjectID, nil)
		}
		if err != nil {
			t.Fatalf("bucket ensuring failed: %v", err)
		}
	}
}

// extractTime extracts the timestamp of s, which must begin with prefix and
// match the form generated by uniqueID. The second return value is true on
// success, false if there was a problem.
func extractTime(s string) (time.Time, bool) {
	if !strings.HasPrefix(s, appPrefix) {
		return time.Time{}, false
	}
	i := strings.LastIndex(s, "_")
	if i < 0 {
		return time.Time{}, false
	}
	nanos, err := strconv.ParseInt(s[:i], 10, 64)
	if err != nil {
		return time.Time{}, false
	}
	return time.Unix(0, nanos), true
}
